#separator:tab
#html:false
#guid column:1
#notetype column:2
#deck column:3
oTHxPp5x]E	Basic	Launch into Computing::Unit 11 - Future-Proofing IT Systems: Integrating Risk Management and Strategic IT Governance	What does artificial intelligence (AI) mean in day‑to‑day business terms?	AI refers to systems that replicate aspects of human behavior—perception, reasoning, learning, and problem‑solving—to automate decisions or augment workers. In practical terms, that means tools that read documents, summarize, classify, predict outcomes, or generate new content (text, images, code) to speed up work.
e3z8,5Vr+g	Basic	Launch into Computing::Unit 11 - Future-Proofing IT Systems: Integrating Risk Management and Strategic IT Governance	How is generative AI different from earlier AI tools?	Generative AI creates new outputs (text, images, audio, code) rather than only classifying or predicting. It supercharges productivity by drafting first versions and brainstorming options, but it also raises distinct risks around data leakage, hallucinations, bias, and over‑reliance on machine‑generated content.
P<E*g:]^ZI	Basic	Launch into Computing::Unit 11 - Future-Proofing IT Systems: Integrating Risk Management and Strategic IT Governance	What headline shifts does AI bring to business operations?	Four shifts dominate: automation of routine tasks, augmentation of human capabilities, creation of new job roles (AI specialists, data engineers, ML engineers, AI ethicists), and continuous reskilling/upskilling so employees can work effectively alongside AI.
FS>gGbL4-]	Basic	Launch into Computing::Unit 11 - Future-Proofing IT Systems: Integrating Risk Management and Strategic IT Governance	Which routine tasks are most likely to be automated first?	Rule‑based, repeatable activities with clear inputs/outputs: data entry, form validation, document processing, reconciliations, standard customer support queries, basic audit checks, and pattern‑based fraud screening. These are prime candidates for AI assistants and RPA (robotic process automation).
w+$R1KZfV7	Basic	Launch into Computing::Unit 11 - Future-Proofing IT Systems: Integrating Risk Management and Strategic IT Governance	How does AI augment—not replace—human work?	It boosts throughput and quality by pre‑analyzing data, proposing options, highlighting anomalies, and compressing time spent on low‑value steps. Humans retain judgment for exceptions, ethics, strategy, and accountability, while AI does the heavy lifting on speed and scale.
I_7Y2.eJ;)	Basic	Launch into Computing::Unit 11 - Future-Proofing IT Systems: Integrating Risk Management and Strategic IT Governance	What new roles appear as AI adoption grows?	Demand rises for AI product owners, prompt engineers, model risk managers, data engineers, ML Ops/SecOps specialists, privacy engineers, and AI ethicists—roles that design, deploy, monitor, secure, and govern AI capabilities across the enterprise.
"QR66#=T*Y6"	Basic	Launch into Computing::Unit 11 - Future-Proofing IT Systems: Integrating Risk Management and Strategic IT Governance	Why is reskilling a critical part of AI programs?	As tasks shift from manual execution to oversight and decision‑making, employees need skills in data literacy, critical thinking, prompt design, basic statistics, privacy/security hygiene, and tool proficiency. Structured learning paths keep talent productive and reduce change resistance.
yZJ;1[`5n1	Basic	Launch into Computing::Unit 11 - Future-Proofing IT Systems: Integrating Risk Management and Strategic IT Governance	Where does AI create immediate value in employee benefit plan administration?	High‑volume processes like eligibility validation, claims triage, contribution/audit checks, exception routing, and fraud detection benefit quickly. AI flags anomalies, drafts correspondence, and prepares summaries; humans review and finalize, cutting cycle time and error rates.
"L3*!aF=#)="	Basic	Launch into Computing::Unit 11 - Future-Proofing IT Systems: Integrating Risk Management and Strategic IT Governance	What privacy and cyber‑risks rise alongside AI adoption?	Key risks include privacy law noncompliance (improper use of personal data), data leakage into AI models, model bias/discrimination, adversarial attacks (poisoning/evasion), unauthorized access to valuable datasets, and over‑reliance on unverified outputs that cause operational or legal harm.
r3I8-tU$Ol	Basic	Launch into Computing::Unit 11 - Future-Proofing IT Systems: Integrating Risk Management and Strategic IT Governance	Why are employee benefit plans especially sensitive to AI risks?	They handle large volumes of sensitive personal and often health‑related data. Misuse or breach can trigger legal exposure (e.g., HIPAA violations), fiduciary liability, regulatory scrutiny, and reputational damage, so stronger oversight, controls, and auditable processes are essential.
A:~5Ge}k.G	Basic	Launch into Computing::Unit 11 - Future-Proofing IT Systems: Integrating Risk Management and Strategic IT Governance	What is the top legal risk when using AI on personal data?	Processing personal and sensitive data without a lawful basis, proper notice/consent, or required contractual safeguards. Organizations must align AI uses with applicable privacy regimes, limit data ingestion to what is necessary, and honor data subject rights.
i3c+m.bUCu	Basic	Launch into Computing::Unit 11 - Future-Proofing IT Systems: Integrating Risk Management and Strategic IT Governance	How should protected health information (PHI) be treated with AI tools?	PHI requires heightened caution: restrict or prohibit AI processing of PHI unless contractual, technical, and procedural safeguards are in place (e.g., Business Associate Agreements, minimum necessary principle, robust access controls, encryption, and audit logging).
A|g<)0<d3*	Basic	Launch into Computing::Unit 11 - Future-Proofing IT Systems: Integrating Risk Management and Strategic IT Governance	What makes AI systems attractive to cybercriminals?	AI centralizes high‑value data and models that inform critical decisions. Attackers target these systems to exfiltrate personal/proprietary data, manipulate models, or cause business disruption, making strong identity, access, and monitoring controls non‑negotiable.
I)S..A!0!R	Basic	Launch into Computing::Unit 11 - Future-Proofing IT Systems: Integrating Risk Management and Strategic IT Governance	What are adversarial attacks in AI and why do they matter?	They are deliberate manipulations of model inputs or training data to induce wrong outputs (e.g., mislabeled claims, bypassed fraud filters). Such attacks can degrade accuracy, undermine trust, or cause financial or safety impacts, so data integrity defenses and model monitoring are vital.
ET|,Z&z@fi	Basic	Launch into Computing::Unit 11 - Future-Proofing IT Systems: Integrating Risk Management and Strategic IT Governance	How does bias enter AI systems?	Bias can stem from skewed training data, proxy variables that stand in for protected attributes, feedback loops, or flawed labeling. Consequences include unfair or discriminatory outcomes in hiring, lending, claims handling, or customer service.
"w#2OPzl5ga"	Basic	Launch into Computing::Unit 11 - Future-Proofing IT Systems: Integrating Risk Management and Strategic IT Governance	What practical steps reduce AI bias?	Apply data minimization and balancing, diverse sampling, fairness metrics, human‑in‑the‑loop reviews, explainability tools, bias audits before/after deployment, clear escalation paths, and continuous monitoring for drift—paired with governance that defines unacceptable impacts.
Nsd0)t9z^k	Basic	Launch into Computing::Unit 11 - Future-Proofing IT Systems: Integrating Risk Management and Strategic IT Governance	What baseline cybersecurity controls should accompany any AI rollout?	Enforce strong identity and access management (least privilege, MFA), encryption in transit/at rest, network segmentation, secure secrets management, vulnerability management, immutable logging with alerting, code/model signing, and user security awareness training.
P[kJBHTuuB	Basic	Launch into Computing::Unit 11 - Future-Proofing IT Systems: Integrating Risk Management and Strategic IT Governance	What organizational moves prepare employees to use AI safely?	Deliver targeted training on acceptable data use, prompt hygiene, validation of outputs, privacy/security do’s and don’ts, and escalation. Encourage curiosity with guardrails, not blanket bans. Provide sanctioned AI tools and an easy way to ask questions and report issues.
t}+xI`BeAR	Basic	Launch into Computing::Unit 11 - Future-Proofing IT Systems: Integrating Risk Management and Strategic IT Governance	How should teams collaborate around AI initiatives?	Create cross‑functional squads that include cybersecurity, privacy, legal, compliance, data science/engineering, operations, and business owners. Involve security and privacy early in tool selection and design so controls are built‑in, not bolted‑on.
AWBF>Jj)|E	Basic	Launch into Computing::Unit 11 - Future-Proofing IT Systems: Integrating Risk Management and Strategic IT Governance	What policy guardrails should every organization have?	Publish a concise AI Use Policy that defines permitted use cases, prohibited data types, review/approval flows, vendor rules, logging/retention, human oversight requirements, and how employees report concerns or suspected misuse.
bP%,bs<+)~	Basic	Launch into Computing::Unit 11 - Future-Proofing IT Systems: Integrating Risk Management and Strategic IT Governance	What three foundational steps help secure AI adoption from day one?	According to the article “Cyber‑Risks in Emerging Technologies: Preparing for the Use of AI,” three cornerstone steps are: (1) carefully negotiate contracts with AI providers; (2) be judicious about what personal information the tool ingests and apply strong privacy/security controls; and (3) create regular opportunities for human oversight and checks on the tool.
DRS&]iNGNV	Basic	Launch into Computing::Unit 11 - Future-Proofing IT Systems: Integrating Risk Management and Strategic IT Governance	What should be negotiated in contracts with AI providers?	Define data ownership/usage rights, model training restrictions, security/privacy obligations, breach notification, audit rights, service levels, indemnities/limitation of liability, subprocessor transparency, data location/transfer terms, and HIPAA/PHI handling where applicable.
"N#/_1>bFH;"	Basic	Launch into Computing::Unit 11 - Future-Proofing IT Systems: Integrating Risk Management and Strategic IT Governance	How should Business Associate Agreements (BAAs) address AI?	Flag AI as higher‑risk processing, restrict model training on PHI, require explicit prior consent for any AI use, mandate strong safeguards (MFA, encryption, access logs), ensure incident reporting timelines, and grant audit and remediation rights to the covered entity.
xPa=U,=5|T	Basic	Launch into Computing::Unit 11 - Future-Proofing IT Systems: Integrating Risk Management and Strategic IT Governance	Which data handling practices lower privacy and security exposure?	Practice data minimization, de‑identify or pseudonymize where possible, segregate environments, restrict copy/paste/uploads to vetted tools, enforce DLP controls, and maintain inventories of datasets, models, prompts, and outputs with retention limits.
E<Nz2by^a)	Basic	Launch into Computing::Unit 11 - Future-Proofing IT Systems: Integrating Risk Management and Strategic IT Governance	Why is human oversight indispensable even with accurate AI?	AI can make confident errors, drift over time, or face edge cases. Human reviews catch hallucinations, ensure fairness, confirm compliance, and provide the accountable decision maker—especially critical for fiduciary obligations in benefit plan contexts.
IC~0^]mvN)	Basic	Launch into Computing::Unit 11 - Future-Proofing IT Systems: Integrating Risk Management and Strategic IT Governance	How do you operationalize human‑in‑the‑loop (HITL) checks?	Define review thresholds and sampling rates, embed approval steps in workflows, assign accountable owners, capture rationale in auditable records, and continuously tune HITL intensity based on risk, error rates, and impact.
hOFIeZ<qe>	Basic	Launch into Computing::Unit 11 - Future-Proofing IT Systems: Integrating Risk Management and Strategic IT Governance	What training themes should be mandatory before granting AI access?	Acceptable use and data classifications, PHI/PII do‑nots, prompt safety, verification techniques, documenting decisions, recognizing bias/adversarial patterns, and when to escalate to privacy/security/legal.
E+?!%/v8|Y	Basic	Launch into Computing::Unit 11 - Future-Proofing IT Systems: Integrating Risk Management and Strategic IT Governance	How can AI improve fraud detection while staying compliant?	Use AI to surface anomalies and patterns; require human review for adverse actions; document criteria; avoid protected‑class proxies; and ensure explainability and appeal processes. Keep models and thresholds under governance to prevent drift into unfair outcomes.
tx-TSi$_{m	Basic	Launch into Computing::Unit 11 - Future-Proofing IT Systems: Integrating Risk Management and Strategic IT Governance	What are telltale signs that an AI vendor may increase risk?	Opaque training data sources, refusal to commit to no‑train on your data, weak security attestations, no breach obligations, limited admin controls, lack of audit logs, no role‑based access, or resistance to fairness/bias testing.
i=!:,}O;@&	Basic	Launch into Computing::Unit 11 - Future-Proofing IT Systems: Integrating Risk Management and Strategic IT Governance	How should access to AI tools be governed internally?	Provision via SSO with MFA, assign least‑privilege roles, segregate development vs. production, restrict external sharing, and require manager approval for datasets, prompts, and integrations that touch sensitive information.
w;O8$CR[Fj	Basic	Launch into Computing::Unit 11 - Future-Proofing IT Systems: Integrating Risk Management and Strategic IT Governance	What metrics indicate a healthy AI risk posture?	Coverage of AI training across staff, % of use cases with signed‑off risk assessments, HITL review pass/fail rates, bias/fairness metrics over time, model/data inventory completeness, incident/near‑miss counts, vendor SLA/aduit findings, and remediation cycle times.
u4DF%U3/DW	Basic	Launch into Computing::Unit 11 - Future-Proofing IT Systems: Integrating Risk Management and Strategic IT Governance	How do you keep AI deployments auditable?	Maintain a living inventory (systems, models, datasets), version models/prompts, archive outputs tied to decisions, retain review logs and rationales, record sign‑offs, and map everything to policies and regulatory requirements for reproducibility.
xb.WBu=$k%	Basic	Launch into Computing::Unit 11 - Future-Proofing IT Systems: Integrating Risk Management and Strategic IT Governance	What change‑management tactics reduce AI adoption friction?	Start with pilot use cases that remove pain points, celebrate quick wins, spotlight “champion” users, co‑design workflows with frontline staff, and provide just‑in‑time training inside the tools, not only in classrooms.
v3x9329V7`	Basic	Launch into Computing::Unit 11 - Future-Proofing IT Systems: Integrating Risk Management and Strategic IT Governance	What’s a simple decision filter before sending any data to an AI tool?	Ask: (1) Is this data classified as restricted (e.g., PHI/PII/confidential)? (2) Do we have legal basis and policy approval to process it? (3) Is the tool on the approved list with proper controls? (4) What is the minimum necessary subset? If any answer is “no/unknown,” stop and escalate.
pYL>4<agI|	Basic	Launch into Computing::Unit 11 - Future-Proofing IT Systems: Integrating Risk Management and Strategic IT Governance	How do you prepare incident response for AI‑related breaches?	Extend IR playbooks to cover model/data compromise, define roles with vendors, pre‑draft regulatory/customer notifications, practice tabletop exercises for prompt leaks, data poisoning, or unauthorized training on your data, and rehearse containment steps.
sES7zndrsO	Basic	Launch into Computing::Unit 11 - Future-Proofing IT Systems: Integrating Risk Management and Strategic IT Governance	What is “data poisoning” and how can it be mitigated?	Data poisoning is malicious tampering with training data to skew model behavior. Mitigate with dataset provenance controls, integrity checksums, canary records, anomaly detection on training data, and retraining/rollback procedures.
F(wa>u/*5M	Basic	Launch into Computing::Unit 11 - Future-Proofing IT Systems: Integrating Risk Management and Strategic IT Governance	How do you reduce dependence on unsanctioned public AI tools?	Provide approved, enterprise‑grade alternatives with privacy controls, integrate them into daily workflows, educate on risks of public uploads, and use CASB/DLP to monitor and block risky destinations.
QEwQ+G~o[5	Basic	Launch into Computing::Unit 11 - Future-Proofing IT Systems: Integrating Risk Management and Strategic IT Governance	When is it appropriate to restrict AI entirely for a use case?	If the process involves highly sensitive data (e.g., PHI without proper safeguards), high stakes decisions with regulatory/fiduciary exposure and no feasible oversight, or vendors that cannot meet contractual/security requirements, choose traditional methods until controls mature.
HRqm;bGrQN	Basic	Launch into Computing::Unit 11 - Future-Proofing IT Systems: Integrating Risk Management and Strategic IT Governance	What are best practices for vendor due diligence on AI tools?	Assess security certifications, architecture diagrams, data flow maps, subprocessor lists, penetration test summaries, SOC2/ISO 27001 reports, privacy impact responses, fairness testing, model governance, uptime/DR plans, and financial/operational resilience.
BR{R!dG=*g	Basic	Launch into Computing::Unit 11 - Future-Proofing IT Systems: Integrating Risk Management and Strategic IT Governance	How can organizations encourage safe innovation with AI?	Create a sandbox for experimentation with synthetic or anonymized data, offer pre‑approved prompts and templates, publish “safe patterns,” and appoint AI champions who coach teams while escalating risks early.
"Hx#Er_~R_$"	Basic	Launch into Computing::Unit 11 - Future-Proofing IT Systems: Integrating Risk Management and Strategic IT Governance	What documentation helps satisfy fiduciary duties when AI is used in benefit plans?	A written rationale for tool selection, privacy and security assessments, BAA/contract clauses, HITL design, testing evidence (accuracy, bias, robustness), training records, and ongoing monitoring reports—showing careful, prudent oversight.
kec,8XY*[&	Basic	Launch into Computing::Unit 11 - Future-Proofing IT Systems: Integrating Risk Management and Strategic IT Governance	How should model performance be monitored over time?	Track accuracy, precision/recall, error types, calibration, drift indicators, and fairness metrics by segment; set retraining triggers; and run periodic red‑team tests and adversarial evaluations to validate resilience.
jxed3[>~XB	Basic	Launch into Computing::Unit 11 - Future-Proofing IT Systems: Integrating Risk Management and Strategic IT Governance	What is the role of a company‑wide AI policy in everyday decisions?	It gives employees a clear reference for what they can/can’t do, which data is off‑limits, when to seek approvals, how to verify outputs, and where to report concerns—reducing ambiguity and inconsistent practices.
A76J{&&6i^	Basic	Launch into Computing::Unit 11 - Future-Proofing IT Systems: Integrating Risk Management and Strategic IT Governance	How can cross‑functional collaboration reduce AI rollout risk?	Jointly define use cases, data needs, and controls so privacy/legal/security requirements are baked in. Regular stand‑ups across IT, security, data, and business teams keep alignment tight and surface issues early.
f6wI_/SC^p	Basic	Launch into Computing::Unit 11 - Future-Proofing IT Systems: Integrating Risk Management and Strategic IT Governance	What is a practical guideline for using AI outputs in customer or member communications?	Treat AI drafts as starting points. Require human review for accuracy, tone, and compliance; include disclaimers where appropriate; and keep an audit trail of edits and approvals tied to the final message.
krC?pmAekB	Basic	Launch into Computing::Unit 11 - Future-Proofing IT Systems: Integrating Risk Management and Strategic IT Governance	How does AI change fraud prevention for benefit plans?	Models can learn complex patterns across claims and contributions to flag anomalies early. Combine with rule‑based controls and human investigation to reduce false positives and ensure fair treatment of members.
Gbn5iD`VEB	Basic	Launch into Computing::Unit 11 - Future-Proofing IT Systems: Integrating Risk Management and Strategic IT Governance	What safeguards limit over‑collection of data for AI?	Define purpose‑specific data lists, apply “minimum necessary,” block unrestricted uploads, require data owner approvals, and employ technical DLP rules that detect PHI/PII in prompts and attachments.
M/X>Ub?MG^	Basic	Launch into Computing::Unit 11 - Future-Proofing IT Systems: Integrating Risk Management and Strategic IT Governance	How do you handle employee curiosity without risking data leakage?	Provide safe demo environments, synthetic datasets, and clear examples of sensitive vs. non‑sensitive prompts. Encourage experimentation within guardrails, and celebrate good questions that surface risk.
pd:?~0mC%S	Basic	Launch into Computing::Unit 11 - Future-Proofing IT Systems: Integrating Risk Management and Strategic IT Governance	What’s a smart approach to evaluating AI tools for PHI use cases?	Start with a risk triage: PHI categories, data flow, storage/retention, vendor capabilities, contract posture, and HITL requirements. If gaps remain, either remediate (BAA, encryption, segregation) or defer the use case.
qpfZ~6oCd5	Basic	Launch into Computing::Unit 11 - Future-Proofing IT Systems: Integrating Risk Management and Strategic IT Governance	Which core principle keeps AI usage defensible under scrutiny?	Accountable human judgment. Even with sophisticated tools, decisions with legal, ethical, or fiduciary impact must have a responsible person who can explain, justify, and, if necessary, reverse the outcome.
Pit1cIQ&OL	Basic	Launch into Computing::Unit 11 - Future-Proofing IT Systems: Integrating Risk Management and Strategic IT Governance	What should leaders communicate about AI to build trust?	Share the vision (why we use AI), the guardrails (how we protect people and data), the expectations (training, oversight, escalation), and the commitment to continuous improvement—inviting feedback and transparency.
P)duq8?7@	Basic	Launch into Computing::Unit 11 - Future-Proofing IT Systems: Integrating Risk Management and Strategic IT Governance	How can organizations get started quickly but safely?	Pilot low‑risk, high‑volume use cases on non‑sensitive data; instrument them with logging and HITL; measure outcomes; capture lessons; and scale with improved controls and policies.
A};:;1}k~i	Basic	Launch into Computing::Unit 11 - Future-Proofing IT Systems: Integrating Risk Management and Strategic IT Governance	What is the single most important takeaway for benefit plan sponsors?	Select AI tools and design processes with built‑in oversight and checks so decisions cannot quietly harm plan members—then document, monitor, and regularly test those safeguards to meet fiduciary duties (per “Cyber‑Risks in Emerging Technologies: Preparing for the Use of AI,” Benefits Quarterly, Q3 2024).

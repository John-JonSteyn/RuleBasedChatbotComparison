#separator:tab
#html:false
#guid column:1
#notetype column:2
#deck column:3
zfRCc1[QfO	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What is artificial intelligence? 	Artificial intelligence is the field of building computer systems that perform tasks requiring human-like cognition—such as perception, reasoning, learning, and decision making—using techniques ranging from rules and search to machine learning and deep learning.
hx`zwH~iIL	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How do symbolic AI and machine learning differ? 	Symbolic AI encodes human knowledge as explicit rules and symbols, whereas machine learning infers patterns from data to map inputs to outputs with minimal hand-crafted rules.
vC+~HYb1M-	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What enabled modern deep learning breakthroughs? 	Increases in data volume, compute (especially GPUs), and algorithmic advances in neural network architectures and optimization unlocked state-of-the-art performance in vision, speech, and language.
g}B2ZgFY8O	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	Where is AI most commonly applied in data analysis? 	AI excels at pattern discovery and prediction in large datasets—fraud detection, customer segmentation, forecasting, anomaly detection, recommendation, and root-cause analysis.
Ed!|7^|qNm	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How does AI enable automation in organizations? 	AI powers robotic process automation to handle repetitive, rules-based tasks and augments human work with decision support, freeing people for higher-value activities.
gpyj/Y5Bi1	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What is natural language processing (NLP) used for? 	NLP lets systems interpret and generate human language for chatbots, summarization, translation, Q&A, sentiment analysis, and information extraction.
<vF0Hovu_	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How is AI transforming health care? 	AI supports earlier diagnosis from images and signals, triage and resource planning via predictive analytics, and personalized treatment recommendations, improving outcomes and efficiency.
P~4uP^|GJ>	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	Why do we need responsible AI? 	We need responsible AI to ensure systems are fair, transparent, privacy-preserving, robust, and aligned with human values so that benefits are widely shared and harms are minimized.
sY4/d$_IeY	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What does it mean to align AI with societal values? 	Aligning AI with societal values means designing, developing, and governing systems so that their goals, constraints, and trade-offs reflect ethical norms like fairness, dignity, autonomy, and accountability.
za2;7MCuLF	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What core principles anchor responsible AI? 	According to Chapter 1 of Introduction to Responsible AI: Implement Ethical AI Using Python, the core principles emphasized are bias and fairness, transparency and explainability, privacy and security, and robustness and reliability.
x|YDTxzw19	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What is algorithmic bias? 	Algorithmic bias is systematic and unfair distortion in model behavior that leads to different outcomes for groups due to issues in data, labels, features, or modeling choices rather than legitimate task requirements.
"e*m?C#PCq3"	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What are common sources of bias in AI systems? 	Sampling bias (unrepresentative data), label bias (subjective or historical prejudice), measurement bias (noisy proxies), aggregation bias (overly uniform models), and deployment bias (context mismatch).
H%*rJy]@8u	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How can we mitigate bias in data? 	Mitigate bias by re-sampling or re-weighting to balance groups, de-duplicating and de-noising records, enriching underrepresented populations, and auditing labels for consistency.
g2uYJ$n=?H	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How can we mitigate bias in models? 	Use fairness-aware learning (constraints or regularizers), adversarial debiasing, separate models per segment when justified, and post-processing (threshold adjustments) to equalize error rates.
C7vIM;acn~	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	Which fairness metrics are commonly used? 	Examples include demographic parity (P(ŷ=1|A=a) equal across groups), equal opportunity (TPR equal across groups), equalized odds (TPR and FPR equal across groups), and calibration (predicted probabilities reflect actual outcomes within groups).
gMNIFChSH,	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How do we choose a fairness metric? 	Select metrics that match the decision context and harms (e.g., equal opportunity for access to beneficial outcomes), legal requirements, and stakeholder priorities; rarely can all fairness criteria hold simultaneously.
uw@S.A{a7%	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What trade-offs arise between accuracy and fairness? 	Fairness constraints can reduce maximum accuracy on the overall population but increase equity by reducing disparate errors; the right balance depends on domain risk, benefits, and values.
IC-+bG-<TT	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What is transparency vs. explainability? 	Transparency is openness about how the system works (data, objectives, design, limits), while explainability is the ability to provide human-understandable reasons for specific predictions or behaviors.
jH|)gwgV9]	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	Why is explainable AI important? 	Explainable AI fosters trust, enables recourse and appeals, supports debugging and compliance, and helps identify bias or failure modes in complex models.
sr4&|Z@S$Z	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What techniques help make models explainable? 	Global tools (feature importance, partial dependence, monotonic constraints, interpretable models like linear/GBM/EBM) and local tools (counterfactuals, LIME, SHAP) translate complex behavior into understandable insights.
"tBudArY0#j"	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How should we document AI systems? 	Use dataset documentation (datasheets), model cards (intended use, metrics, fairness, limitations), decision logs, and data lineage so stakeholders can evaluate suitability and risks.
n4Ay=vb:]S	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What is privacy by design? 	Privacy by design embeds data minimization, purpose limitation, consent, security, and auditability into the system from the outset rather than adding them later.
qy@Sps~YE<	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What is data minimization? 	Data minimization is collecting, processing, and retaining only the data necessary for the stated purpose, with strict retention schedules and access controls.
d6HX|0A+}L	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	Which privacy-preserving techniques are highlighted? 	According to Chapter 1 of Introduction to Responsible AI: Implement Ethical AI Using Python, privacy-preserving learning techniques such as federated learning and homomorphic encryption can enable learning from decentralized or encrypted data without exposing raw personal information.
j[hf0{IER0	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How do we secure AI data pipelines? 	Apply encryption in transit and at rest, strong identity and access management, key rotation, network segmentation, secure enclaves when appropriate, and immutable audit trails.
QYEa(^RZaA	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What is robustness in AI? 	Robustness is the ability of a model to maintain acceptable performance under shifts, noise, missing data, or adversarial perturbations and across diverse real-world conditions.
d$_Pd8&OA:	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What is reliability in AI? 	Reliability is the consistency of correct operation and predictions over time, including uptime, predictable degradation, and safe failure behavior with clear alerts.
M|^)s2>^i`	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How can we improve robustness? 	Use diverse training data, stress tests and worst-case evaluation, data augmentation, adversarial training, input validation, and out-of-distribution detection with fallback strategies.
f/}oz{]Goe	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What are adversarial examples? 	Adversarial examples are inputs modified by small, often imperceptible changes crafted to cause a model to make incorrect predictions, revealing sensitivity to perturbations.
z{YTVjVG8x	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How should models be monitored in production? 	Continuously track performance, data and concept drift, fairness metrics, rates of outliers and rejections, latency, and reliability; set alerts and retraining or rollback triggers.
"f](d#}QYIO"	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What is human-in-the-loop and why use it? 	Human-in-the-loop keeps people involved in critical steps—reviewing edge cases, approving high-risk decisions, labeling new data—which improves safety, accountability, and adaptation.
C|_KO(rKYR	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How can we provide user recourse for automated decisions? 	Offer clear explanations, appeal channels, human review on request, and actionable counterfactual guidance (e.g., which features to change) within reasonable timeframes.
G~}sSd?E(@	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What governance structures support responsible AI? 	Establish cross-functional AI risk reviews, ethics guidelines, model registries, incident response playbooks, and accountability for owners throughout the model lifecycle.
w%xPge$&t2	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How do we balance transparency and proprietary constraints? 	According to Chapter 1 of Introduction to Responsible AI: Implement Ethical AI Using Python, transparency should be maximized while safeguarding legitimate IP and security needs by sharing methods, limits, and aggregate behaviors even when source code or data cannot be exposed.
AjQ@dgLBqY	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How does explainability relate to trust? 	According to Chapter 1 of Introduction to Responsible AI: Implement Ethical AI Using Python, explainable decisions make systems comprehensible and traceable, which supports informed user consent, oversight, and trust.
q16%c8iqQ*	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What practical steps start a responsible AI project in Python? 	Define purpose and harms; draft a model card template; collect and profile data with pandas; split by time/population; baseline models with scikit-learn; evaluate accuracy and fairness; add explainability (e.g., SHAP); harden privacy/security; plan monitoring and retraining.
N8{i$a1YP~	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What documentation should accompany datasets? 	Datasheets should describe provenance, collection methods, consent, known biases, recommended uses, limitations, and legal constraints to inform downstream users.
p0zhrRv^LC	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What is an algorithmic audit? 	An algorithmic audit is an independent, systematic evaluation of an AI system’s data, models, processes, and outcomes against criteria for fairness, privacy, security, and reliability, with evidence and recommendations.
"qyf#I].75z"	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How do we measure AI value ethically? 	Combine utility metrics (e.g., cost saved) with harm and equity metrics (e.g., false-negative rates by group) and report distributional impacts, not just averages.
D;94|@(F2D	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How do we include diverse stakeholders? 	Engage impacted communities early, solicit domain and lived-experience input, co-design evaluation criteria, and incorporate feedback loops into governance.
t;1,^1@rVZ	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	Can we eliminate all bias in AI? 	According to Chapter 1 of Introduction to Responsible AI: Implement Ethical AI Using Python, eliminating all bias may be infeasible; the ethical aim is to identify, reduce, and manage harmful bias while monitoring residual risks.
QQwcG>_/t1	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	Why keep human oversight for high-performing models? 	According to Chapter 1 of Introduction to Responsible AI: Implement Ethical AI Using Python, human oversight is essential to handle ambiguity, value trade-offs, and accountability, ensuring AI remains an enabler rather than an unchecked authority.
"wZ#E]dkcU5"	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How do we balance privacy and innovation? 	According to Chapter 1 of Introduction to Responsible AI: Implement Ethical AI Using Python, responsible AI seeks equilibrium by protecting individual rights (consent, minimization, security) while enabling beneficial data use through safeguards and privacy-preserving methods.
F`pZIW}kmv	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What does accountability mean in AI practice? 	Accountability means assigning clear responsibility for outcomes, documenting decisions, enabling audits, and providing remedies when harms occur.
y>t/|b`}o%	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How do we prepare for regulatory compliance? 	Maintain traceability (data lineage, model versions), keep risk assessments and DPIAs, log decisions and consent, and establish processes to honor access/erasure requests.
wK)j_N.e*y	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What deployment pitfalls commonly cause harm? 	Data leakage, spurious correlations, training–serving skew, untested edge cases, and shifting populations can degrade fairness and safety if not monitored and mitigated.
DoDlvg3O28	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What makes consent meaningful in data collection? 	Consent is meaningful when it’s informed, specific, opt-in, freely given, documented, revocable, and paired with clear alternatives and minimal coercion.
r5n_6Rc[/h	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How can we share data responsibly? 	Use purpose-limited agreements, robust de-identification with re-identification risk assessments, synthetic data when appropriate, and secure computing environments for access.
p<:XVoB}Wa	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How should we track multi-objective success? 	Use a scored dashboard, e.g., S = w1*Accuracy + w2*FairnessGapReduction − w3*Latency − w4*IncidentCount, with weights set collaboratively and reported over time.
AZde%]J;D^	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What belongs in a minimal model card? 	State intended use and users, training data summary, performance by segment, fairness testing results, uncertainty and limitations, monitoring plan, and contact for issues.
"w%SHz#Z;I>"	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What role do awareness and education play? 	According to Chapter 1 of Introduction to Responsible AI: Implement Ethical AI Using Python, awareness and education are pivotal for recognizing bias, understanding consequences, and building the skills to apply mitigation and governance effectively.
n[(%Y2SnpE	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How do robustness and reliability interact with safety? 	Robust, reliable systems reduce unexpected failures and facilitate safe fallback modes, incident detection, and graceful degradation under stress, protecting users and organizations.
rHbpnb5~z<	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What is the overarching goal of responsible AI? 	The overarching goal is to realize AI’s benefits while safeguarding people and society—delivering useful, fair, secure, explainable, and dependable systems that respect human rights and earn trust.
QSl@AHfC<,	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What does “bias in data and models” mean?	Bias in data and models refers to systematic deviations that cause inaccurate or unfair outcomes when making decisions. It can arise from how data were collected (e.g., sampling or measurement errors) or how models were built (e.g., learning spurious associations). In short, biased inputs or learning processes produce predictions that favor or disadvantage certain groups beyond legitimate, task‑relevant differences.
EX:WKS(o?Y	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	Why is understanding bias essential for building fair AI systems?	Understanding bias is essential because it helps prevent discriminatory outcomes, aligns development with ethical and legal norms, builds public trust, improves decision quality, spurs innovation by better representing diverse users, avoids repeating historical injustices, encourages inclusive teams and designs, and sustains long‑term adoption of AI in sensitive domains like health, finance, and education.
"JKLg.{H,k#"	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How can bias distort decision‑making processes in practice?	Bias can distort perceptions (what evidence we attend to), amplify unconscious/implicit preferences, drive confirmation bias (we over‑weight evidence that fits our prior beliefs), fuel stereotyping (we generalize from group labels), and produce unequal treatment and discriminatory outcomes. In automated systems, biased training data lead to biased predictions, which can create feedback loops that entrench inequity and erode trust.
sxp>|;Y7Ld	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What are the major types of bias relevant to machine learning?	Three broad families are common: (1) Data bias—sampling bias, measurement bias, and coverage bias; (2) Model bias—representation bias, algorithmic bias, and feedback‑loop bias; and (3) Social bias—cultural, gender, racial, and economic factors reflected in the data and in modeling choices. Each can manifest at different stages of the ML pipeline and may compound.
rY$p<P$rVZ	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	Give concise definitions of common fairness metrics used to detect bias.	Let Y be the true label (1/0), Â the prediction (1/0), and A a protected attribute (e.g., group g vs. reference r).
h_N/0`4KM<	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What simple diagnostics should teams run before training to uncover bias?	Run stratified exploratory data analysis (EDA): check sample sizes by protected classes; compare missingness rates; inspect label base rates across groups; visualize feature distributions by group; compute target leakage checks; and simulate baseline fairness metrics (e.g., SPD, DI) with trivial predictors to understand structural skews in the dataset.
F~H{t,{L@i	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How do class imbalance and representation gaps create biased models?	If a minority group has far fewer examples or noisier labels, the model optimizes overall loss by fitting the majority, degrading minority performance. This can yield lower TPR, higher FNR, or unstable thresholds for the minority, even when overall accuracy looks strong.
CS^Cq`U*1,	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What practical techniques help detect bias prior to deployment?	Use fairness dashboards with: (1) group disparity analysis of outcomes; (2) fairness metrics (SPD, DI, EOD, AOD); (3) sensitivity tests (perturb features; simulate shifts); (4) proxy‑variable scans (features highly correlated with protected attributes); (5) interpretability (feature importance, SHAP) to spot problematic drivers; and (6) human review with diverse evaluators. According to Chapter 2 of *Introduction to Responsible AI: Implement Ethical AI Using Python*, the text emphasizes combining EDA, fairness metrics, and qualitative review to surface issues early.
"d-MI8sD^#9"	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What are common, real‑world failure modes that illustrate biased behavior?	Well‑documented cases include: gender bias in automated résumé screening, racial disparities in criminal risk scores, mislabeling of images of Black people in early photo taggers, biased loan approval models, and higher misidentification rates for darker‑skinned women in facial recognition. These failures show how historical data and skewed representations can propagate harm.
h^tJcj.y-K	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	Which mitigation tactics operate at different stages of the ML pipeline?	• Pre‑processing: reweighting, resampling/upsampling, data augmentation, de‑biasing encodings, label‑noise audits, and fair feature engineering.
LeNYyP2bMk	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What is resampling, and when is it appropriate?	Resampling alters the class distribution to reduce imbalance—either by oversampling the minority, undersampling the majority, or synthesizing new points (e.g., SMOTE). It’s appropriate when performance gaps track raw class counts and when the signal is not overwhelmed by noise. Care is needed to avoid overfitting and to maintain a realistic data distribution.
EZ_Opa31zc	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How does adversarial debiasing work conceptually?	Adversarial debiasing trains two networks: a predictor to minimize task loss and an adversary to maximize its ability to infer the protected attribute from the predictor’s internal representation or outputs. The predictor is optimized to both perform the task and fool the adversary, discouraging the encoding of protected‑attribute information and reducing group disparities.
v2.!?hM`^7	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What trade‑offs should we expect when adding fairness constraints?	Fairness constraints can shift the operating point and sometimes modestly reduce overall accuracy while improving group equity (e.g., narrowing EOD/AOD gaps). Teams should make the trade‑offs explicit with Pareto curves (accuracy vs. fairness metric), check downstream utility, and document chosen thresholds and justifications.
jIQSnbEkO<	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How do we quantify harms that overall accuracy can hide?	Report per‑group confusion matrices and derived rates:
"Qx2<3S#!*E"	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What governance guardrails help ensure responsible bias management?	Adopt a lifecycle process: define use‑case and harm model; set fairness goals and metrics up front; require data sheets and model cards; run pre‑release fairness audits; monitor post‑deployment drift and disparities; enable recourse and appeals; and conduct periodic re‑training with refreshed, representative data. According to Chapter 2 of *Introduction to Responsible AI: Implement Ethical AI Using Python*, the chapter pairs detection (metrics, audits) with mitigation (resampling, adversarial debiasing) and stresses continuous evaluation.
A)TyEc(OeO	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How can explainable AI (XAI) support fairness work without overpromising?	Use local explanations (e.g., SHAP) to see which features drive predictions for an individual and global summaries to identify systematically influential features. Explanations can reveal proxies for protected attributes, support data cleaning, and justify threshold policies. Still, explanations do not prove fairness; they complement, not replace, quantitative disparity testing.
yZ5=z$xx|2	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What are sensible acceptance targets for common fairness metrics?	Targets are context‑dependent and should be set with domain and legal input. Examples: DI within [0.8, 1.25]; |SPD| ≤ 0.05; |EOD| ≤ 0.02–0.05; |AOD| ≤ 0.02–0.05. Record rationale, confidence intervals, and business impact for any deviations.
mA34n[aK@x	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How do feedback loops entrench bias, and how can we break them?	If model outputs influence future labels or data availability (e.g., allocating fewer resources to a group), future training data will reflect those skewed decisions. Break loops by randomized audits, counterfactual data collection, off‑policy evaluation, and periodic re‑labeling with blinded reviewers to restore signal quality across groups.
B0N7d+/YD[	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What does the AIF360 debiasing exercise demonstrate about model bias?	Training an adversarially debiased classifier can reduce disparity metrics (e.g., disparate impact closer to parity, smaller equal opportunity and average odds gaps) while sometimes slightly lowering overall accuracy. This makes the fairness–accuracy trade‑off visible and measurable so stakeholders can make informed choices. According to Chapter 2 of *Introduction to Responsible AI: Implement Ethical AI Using Python*, the debiased model improved equity metrics versus the naive model on the same test set.
dD,$-%F@oU	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How should teams decide among mitigation strategies?	Prefer minimal, data‑centric fixes first (clean labels, fix leakage, resample or reweight, add missing cohorts), then try in‑processing constraints, and finally consider post‑processing adjustments when re‑training isn’t possible. Evaluate each candidate with holdout fairness metrics, stability across seeds, and business KPIs; pick the approach that achieves fairness targets with least disruption and clear documentation.
P~&_*vVZj!	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What documentation should accompany fairness work?	Provide: (1) problem statement and context; (2) protected attributes and reasons; (3) datasets, sampling frames, label provenance; (4) model family, features, and known proxies; (5) pre‑/post‑mitigation metrics by group; (6) thresholds and calibration strategy; (7) expected harms, recourse paths, and monitoring plan; and (8) residual risks and open questions.
wmtyrU@<(}	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What is the role of human‑in‑the‑loop in mitigating bias?	Humans should set goals, review explanations in high‑stakes decisions, adjudicate appeals, and oversee periodic audits. Human oversight helps catch context‑specific harms that metrics miss, and it provides accountability when trade‑offs are non‑technical.
dFfacFML61	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How can organizations monitor bias after deployment?	Instrument live systems to log predictions, outcomes, and protected‑group proxies (where lawful) or reliable surrogates. Compute fairness metrics on rolling windows, trigger alerts on threshold breaches, run shadow models, and schedule re‑training or policy updates as needed. Establish governance to pause or rollback when harms are detected.
CyZ8ap~J(m	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What are practical tips for engineering fairness into production systems?	Version data and metrics; build unit tests for fairness calculations; add CI checks for parity thresholds; expose per‑group telemetry; support per‑segment thresholds and calibration; implement feature and label drift detection; and design safe‑fallback behavior (e.g., defer to manual review) when fairness alarms trigger.
"k={ke(X1#W"	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	When is it appropriate to refuse to automate a decision?	If harms are severe and unavoidable, labels are unreliable, protected attributes are entangled with outcomes in ways you cannot reconcile, or governance cannot provide timely oversight and recourse, the responsible choice is to keep humans in control and use AI only for decision support—not automation.
L{VYw)bt$j	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What is transparency in artificial intelligence?	Transparency in artificial intelligence refers to the openness and clarity with which an AI system's decision-making process can be understood. It involves revealing the internal mechanisms, algorithms, and data used by the system to arrive at conclusions, allowing stakeholders to understand why a particular decision was made.
t=]K5XvMGy	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What is explainability in AI?	Explainability in AI extends beyond transparency by providing understandable explanations for the decisions made by AI systems. It focuses on describing the factors, features, or data points that influenced a particular output, enabling users to comprehend and trust the reasoning behind an AI’s actions.
e|b/Q.(TuO	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	Why are transparency and explainability important in AI?	Transparency and explainability are essential because they foster trust, accountability, and ethical decision-making in AI systems. They ensure that users and stakeholders understand how AI models operate, can verify their fairness, and can identify potential biases or errors in decision-making processes.
A]TiB]={Af	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How does transparency build trust in AI systems?	Transparency builds trust by allowing users and stakeholders to see how an AI system arrives at its conclusions. When people can understand the underlying logic and data behind AI decisions, they are more likely to trust its outcomes, particularly in high-stakes domains such as healthcare or finance.
"Jp/#FTEUvB"	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How do transparency and accountability relate to each other in AI?	Transparency and accountability are interconnected. When an AI system is transparent, developers and organizations can be held accountable for its outputs and decisions. Transparent systems allow auditing, error tracking, and regulatory compliance, ensuring responsible and ethical AI deployment.
v:QbR,{5;*	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How does transparency help in mitigating AI bias?	Transparency helps in mitigating AI bias by revealing how models are trained and what data they rely on. By understanding the inner workings and decisions of AI models, developers can identify and correct patterns of discrimination or unfair treatment embedded in the algorithms or training data.
C+(:!9jGkh	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How does explainability contribute to informed decision-making?	Explainability contributes to informed decision-making by providing clear reasoning for AI-generated outputs. For instance, in medicine, doctors can better evaluate AI-based diagnoses if they understand which factors influenced the AI’s recommendation. This empowers professionals to make decisions supported by both human expertise and AI insights.
um`Hz<L@}8	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What role do transparency and explainability play in detecting AI errors?	Transparent and explainable AI systems make it easier to detect and correct errors. When decision paths and influencing features are visible, anomalies can be identified and investigated quickly, leading to continuous improvements and more reliable AI performance.
e8g|h<hJGd	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How does transparent AI impact healthcare?	In healthcare, transparent AI enhances diagnostic accuracy and trust. For example, IBM’s Watson for Oncology provides explanations for its treatment recommendations, enabling doctors to understand the reasoning behind them. This builds confidence in AI-assisted medical decisions and fosters better doctor-patient communication.
e=dZz-2ujq	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How does transparent AI improve fairness in financial decision-making?	Transparent AI in finance helps promote fairness by making decision criteria visible. Systems like Upstart’s credit scoring AI provide explanations for loan decisions, allowing lenders to verify that creditworthiness is determined fairly and not biased against individuals with limited credit histories.
jIfua]SSqe	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How does transparent AI address bias in criminal justice systems?	Transparent AI can mitigate bias in criminal justice by clarifying how risk assessments are made. For instance, the Stanford Computational Policy Lab developed transparent models that explain recidivism risk predictions, helping judges and defendants understand outcomes and challenge unfair assessments.
tYY<c{-d^9	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What is the purpose of explainable AI (XAI)?	The purpose of Explainable AI (XAI) is to make complex machine learning models more interpretable and understandable. XAI techniques aim to bridge the gap between the high accuracy of complex models and the human need for interpretability, ensuring AI systems remain accountable and trustworthy.
*2C~K%=GD	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What are some explanation methods for interpretable models?	Some explanation methods for interpretable models include decision trees and rule-based systems. Decision trees explain predictions by tracing decision paths from root to leaf nodes, while rule-based systems use human-readable if-then rules to describe how inputs lead to outputs.
Mr<MXHYM&&	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How do decision trees provide explainability?	Decision trees provide explainability by showing the sequence of decisions that lead to a prediction. Each node represents a decision point based on a feature, allowing users to follow the tree path to understand how specific inputs influenced the final outcome.
rZzD%O<KyA	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What is feature importance in machine learning models?	Feature importance quantifies the influence of each input variable on a model’s predictions. It indicates which features contribute most to decision outcomes, helping users interpret the model’s behavior and identify key drivers behind predictions.
"n5nt)%xO#O"	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What are permutation importance and mean decrease impurity?	Permutation importance measures the drop in model performance when a feature’s values are shuffled, showing how much the model depends on that feature. Mean decrease impurity, used in decision trees, evaluates how much a feature reduces uncertainty (impurity) in the dataset when making splits.
b+6+@tHsF[	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What are local explanations in machine learning?	Local explanations interpret the decision-making process for individual instances rather than the entire dataset. They show which features influenced a specific prediction, providing personalized explanations for each case.
sPHAqQ}IHF	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What is LIME and how does it work?	LIME (Local Interpretable Model-agnostic Explanations) explains individual predictions by creating a simplified model that approximates the complex model’s behavior near the instance of interest. It perturbs the input data to observe how changes affect predictions, identifying the most influential features locally.
iypKmo44>f	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What is SHAP and what makes it powerful?	SHAP (SHapley Additive exPlanations) is a method based on game theory that assigns each feature a contribution value toward the final prediction. It provides consistent and fair explanations by considering all possible feature combinations, offering both local and global interpretability.
oqmsZdwnA%	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What are saliency maps in explainable AI?	Saliency maps are visual tools that highlight which parts of the input data most influence a model’s prediction. In image recognition, for example, saliency maps show the regions of an image that contributed most to the AI’s classification, improving interpretability.
"L8-#0uJXCr"	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What is InterpretML used for?	InterpretML is an open-source library designed to make machine learning models more interpretable. It supports multiple interpretability methods, including SHAP and LIME, and provides visualizations that help explain model predictions in both global and local contexts.
eZ*Mt0F?(t	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What does TensorBoard offer for AI transparency?	TensorBoard, developed by Google, provides visualization tools for TensorFlow models. It allows users to inspect training metrics, model architectures, and layer activations, helping data scientists understand and debug model behavior through visual insights.
l(+$juMvkK	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What is the SHAP library used for?	The SHAP library computes Shapley values to explain model predictions by quantifying each feature’s contribution. It works across various model types and provides unified, mathematically grounded explanations that enhance interpretability.
toj4&ECUri	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What is the LIME library used for?	The LIME library is used to generate interpretable, local explanations for individual predictions made by black-box models. It helps users understand which input features influenced a specific prediction by training surrogate models around that instance.
y]HT?+YcK*	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How does the ELI5 library contribute to explainable AI?	ELI5 (Explain Like I’m 5) is a Python library that simplifies model interpretation by displaying feature weights, importance scores, and prediction contributions in human-readable formats. It supports various models, making it accessible for debugging and explanation purposes.
bEWLT^d9nO	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What is the Yellowbrick library used for?	Yellowbrick is a visualization library that assists in understanding machine learning models by providing tools to visualize model performance, feature importance, and residual errors. It integrates with Scikit-Learn and helps users interpret model behavior visually.
qj=_YJb@db	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	Why is balancing model performance and explainability important?	Balancing model performance and explainability is crucial because highly accurate models are often complex and difficult to interpret, while simpler models are easier to understand but may sacrifice accuracy. Striking a balance ensures that AI systems remain both effective and transparent.
EF?=-m?Q1{	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What is the black-box nature of AI models?	The black-box nature of AI models refers to their lack of interpretability. Complex models like deep neural networks can make highly accurate predictions, but their internal workings are so intricate that humans cannot easily understand how decisions are made.
"QB=P/l#%qH"	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How can model-agnostic techniques improve interpretability?	Model-agnostic techniques, such as LIME and SHAP, improve interpretability by providing explanations independent of the underlying algorithm. They can be applied to any model to reveal how different features influence predictions, enhancing transparency without altering the model’s structure.
Ew3)yb<(Vd	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What is the accuracy-interpretability trade-off in AI?	The accuracy-interpretability trade-off refers to the balance between a model’s predictive performance and how easily its decisions can be understood. More accurate models tend to be more complex and opaque, while interpretable models are simpler but may be less precise.
bHY(Lhpe)U	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How do visual tools support transparency in AI?	Visual tools, such as SHAP summary plots, saliency maps, and dependence plots, make AI decisions more transparent by showing how features influence predictions. They enable users to intuitively grasp complex model behaviors and build trust through visual explanations.
"N(#aX;iOm{"	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What are the benefits of explainable AI in real-world applications?	Explainable AI enhances accountability, builds trust, improves fairness, and enables error detection. It empowers stakeholders to make informed decisions and ensures that AI-driven outcomes are consistent with ethical and regulatory expectations.
BdLZH;_V|c	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What are common challenges in achieving AI transparency?	Common challenges include the complexity of deep learning models, trade-offs between performance and interpretability, data biases, and the difficulty of explaining non-linear feature interactions in a human-understandable way.
"K6`UX|b#1p"	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What is the purpose of surrogate models in explainability?	Surrogate models are simpler, interpretable models trained to approximate the predictions of complex black-box models. They provide insight into how the complex model behaves by offering an accessible approximation of its decision-making logic.
ER2sw:QYTo	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What are counterfactual explanations in AI?	Counterfactual explanations describe how altering certain input features could change the model’s prediction. They help users understand the sensitivity of model outputs and what modifications could lead to different outcomes, supporting interpretability and fairness.
IO5T`x/B3S	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	Why is transparency critical for AI regulation?	Transparency is essential for AI regulation because it enables auditors and regulators to assess compliance with ethical, legal, and fairness standards. Transparent systems allow verification of how decisions are made, ensuring accountability and public trust.
e71}r/NS+	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How do explainability techniques help mitigate ethical concerns in AI?	Explainability techniques help mitigate ethical concerns by exposing biases, errors, or unintended consequences in model behavior. By understanding why an AI system makes a decision, developers can correct harmful patterns and align AI outputs with ethical standards.
JTOk>>}Gwy	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	Why is responsible AI important for society?	Responsible AI ensures that artificial intelligence is developed and deployed in a way that benefits society while minimizing harm. It prioritizes fairness, accountability, and transparency to promote ethical decision-making and prevent discrimination or misuse of technology.
dGUBpYHZwl	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What is the main focus of AI privacy and security?	The main focus of AI privacy and security is to protect sensitive data handled by AI systems and ensure that these systems remain resilient against malicious attacks, unauthorized access, and misuse, thereby maintaining confidentiality, integrity, and trust.
eY,ad.,sq;	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	Why is data considered the 'new oil' in the digital era?	Data is considered the 'new oil' because it fuels the functioning of modern technologies, particularly AI systems, by providing the raw material needed for training models, extracting insights, and driving innovation across industries.
id.avOrVsn	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What is the relationship between AI and privacy?	AI and privacy are closely linked because AI systems rely on vast amounts of personal data to function effectively, raising ethical and legal concerns about how this data is collected, used, and protected from misuse or unauthorized access.
k`.6kn=9$|	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	Why is privacy a critical concern in AI systems?	Privacy is critical in AI systems because they often process sensitive personal information such as medical records, financial details, or behavioral data, which, if exposed or misused, could lead to identity theft, discrimination, or other harms.
cy=$ktDl/%	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What are potential privacy threats in AI systems?	Potential privacy threats in AI systems include data breaches, unauthorized access, misuse of personal data, and inadvertent sharing of sensitive information through model outputs or data leaks.
Ml.Ay<[P3T	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How do data breaches threaten AI privacy?	Data breaches threaten AI privacy by exposing sensitive data stored in or processed by AI systems to unauthorized users, potentially leading to identity theft, fraud, and reputational damage to organizations.
k|90g_a,ni	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What is an example of a real-world data breach affecting AI systems?	An example is the 2019 Capital One data breach, where a misconfigured cloud firewall allowed unauthorized access to personal information of over 100 million customers, highlighting the risks of cloud-based AI systems.
"rUx4w=#CQD"	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How can misuse of personal data by AI models occur?	Misuse of personal data can occur when AI models use data for purposes not consented to by users, such as repurposing facial recognition data for surveillance or data mining without explicit permission.
[&qSgAMUI	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What is an inadvertent disclosure of sensitive information in AI?	An inadvertent disclosure occurs when AI models unintentionally reveal private data, such as when natural language models trained on sensitive datasets generate outputs that expose personal or confidential information.
P<.8~J@GIh	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	Why is the balance between AI utility and privacy important?	The balance is important because while AI systems need data to function effectively, excessive or unethical use of personal data can violate privacy rights, eroding public trust and leading to regulatory violations.
GP]ZXAuT9A	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What are the main types of privacy attacks in AI models?	The main types of privacy attacks include data re-identification, inference attacks, membership inference attacks, and model inversion attacks, all of which exploit vulnerabilities to extract sensitive information.
G>WkgtZ%19	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What is a data re-identification attack?	A data re-identification attack occurs when anonymized data is cross-referenced with other datasets to re-identify individuals, undermining privacy protections.
b]h;98K%J>	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What is an inference attack in AI?	An inference attack occurs when attackers deduce sensitive information about individuals from AI model outputs, even when such details are not explicitly included in the data.
utE7d~Vnh/	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What is a membership inference attack?	A membership inference attack allows an attacker to determine whether specific data points were part of a model’s training set, potentially revealing private information about individuals.
Q>eQZoCk~a	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What is a model inversion attack?	A model inversion attack involves reconstructing sensitive attributes of the training data from the model’s outputs, allowing attackers to infer personal or confidential details.
DlSnf?XApB	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	Why are privacy attacks dangerous in AI systems?	Privacy attacks are dangerous because they exploit AI models’ data dependencies, allowing attackers to extract or infer sensitive information, violating privacy and potentially leading to legal and ethical issues.
G2+x%+oILe	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How can privacy risks in AI be mitigated?	Privacy risks can be mitigated using techniques such as data anonymization, encryption, differential privacy, secure multi-party computation, and robust user consent mechanisms.
"C|tS=E#zG["	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What is data anonymization in AI?	Data anonymization is the process of modifying data so that individuals cannot be identified, often using methods like k-anonymity, l-diversity, t-closeness, data masking, and perturbation.
m{+BgmB%e~	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What is k-anonymity?	k-anonymity ensures that each record in a dataset is indistinguishable from at least k−1 other records by generalizing or suppressing identifying attributes, reducing the risk of re-identification.
qPl{ej!h1>	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What is data encryption in AI systems?	Data encryption converts readable data into an encoded form that can only be accessed or decrypted by authorized parties, protecting it from unauthorized access during storage and transmission.
oqZ%{c}R,O	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How does encryption enhance AI privacy?	Encryption enhances privacy by ensuring that sensitive data remains inaccessible to unauthorized users even if intercepted or breached, thereby maintaining confidentiality and data integrity.
jqx]1z0;O=	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What is differential privacy?	Differential privacy is a mathematical framework that protects individual data points in a dataset by adding controlled noise to outputs, ensuring that no single record can be distinguished or reverse-engineered from model results.
Gcu(?0qmxf	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How does differential privacy protect AI models?	Differential privacy protects AI models by limiting the information leakage from training data, making it statistically impossible to determine whether any specific individual’s data was included in the dataset.
js=/NY1$Cs	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What is the privacy budget in differential privacy?	The privacy budget, denoted by epsilon (ε), controls the trade-off between privacy and accuracy in differential privacy. Smaller ε values offer stronger privacy protection but can reduce model utility.
MGVSAA<{(*	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What is secure multi-party computation (SMPC)?	Secure multi-party computation (SMPC) is a cryptographic method that allows multiple parties to compute a joint function on their data without revealing their individual inputs, ensuring data confidentiality during collaboration.
"OWuqO(0&r#"	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How does SMPC improve data security in AI?	SMPC improves security by enabling distributed AI training and analysis without transferring raw data, minimizing risks of exposure, breaches, and unauthorized access.
e;{R*5Jpq0	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What are the limitations of SMPC?	The limitations of SMPC include high computational and communication overhead, which can make it impractical for large-scale or real-time AI systems.
mp`kUSU]})	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What is the importance of user consent in AI?	User consent ensures ethical and legal use of personal data by granting individuals control over how their information is collected, stored, and used, reinforcing transparency and trust.
Hp@/m}W$ME	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	Why must consent forms be clear and dynamic?	Consent forms must be clear to ensure users understand how their data will be used and dynamic to allow users to withdraw or modify their consent as systems evolve or data usage changes.
r8@w]!fl>4	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What is transparency in AI privacy management?	Transparency in AI involves clearly communicating how data is collected, processed, and used, and providing insight into how AI models make decisions that affect users.
C_`e>D1C`A	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	Why is transparency vital for AI ethics?	Transparency is vital because it empowers users to make informed decisions, ensures accountability, and builds trust by revealing the inner workings and decision logic of AI systems.
c=$qKt8tlm	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How can dashboards promote transparency in AI systems?	Dashboards can promote transparency by allowing users to view how their data is used in real time, monitor AI decisions, and control or limit data sharing preferences.
pDY%d$,VT`	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What are the main goals of AI security?	The main goals of AI security are to protect models and data from manipulation, theft, and misuse while ensuring the system’s reliability, integrity, and trustworthiness.
q+o3Je~&sb	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What are common security threats in AI systems?	Common security threats include adversarial attacks, data poisoning, evasion attacks, backdoor attacks, model inversion, and model extraction, all of which can compromise AI reliability and integrity.
Kwr4u7>):`	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What are adversarial attacks?	Adversarial attacks involve intentionally adding small perturbations to input data to mislead AI models into making incorrect predictions or classifications.
I2Dti)d:{;	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What is data poisoning in AI?	Data poisoning occurs when malicious actors tamper with training data to corrupt the learning process, leading to biased or incorrect AI model behavior.
Ngj<tUK&U!	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What is a backdoor attack in AI?	A backdoor attack introduces hidden triggers into an AI model during training so that the model behaves normally under standard conditions but produces malicious outputs when the trigger is present.
"qfhm#bv&:{"	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What is an evasion attack?	An evasion attack manipulates input data during inference to deceive the model into misclassifying it, as in modifying malware to bypass AI-based security systems.
JyPciA9/t5	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What is model extraction?	Model extraction is an attack in which adversaries replicate a proprietary AI model by querying it repeatedly and using the responses to reconstruct its behavior or architecture.
sT[2V&5WY`	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How can adversarial training defend AI systems?	Adversarial training strengthens AI models by exposing them to adversarial examples during training, allowing the model to learn to resist such manipulations.
ogGRy0{<iL	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What is gradient masking in AI defense?	Gradient masking is a defense mechanism that obscures the gradients used to generate adversarial examples, making it more difficult for attackers to exploit model weaknesses.
p$pH<P|q{.	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What is feature squeezing?	Feature squeezing is a pre-processing technique that reduces the complexity of input data, such as color depth or resolution, making it harder for adversarial noise to influence model predictions.
K,5As)x<7L	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What is model hardening?	Model hardening involves applying strategies such as rate limiting, model obfuscation, ensembling, and regularization to make AI models more resilient to extraction, tampering, or reverse engineering.
lM>cbXeMSP	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How can ensembles increase AI robustness?	Ensembles improve robustness by combining predictions from multiple models, making it harder for adversarial attacks to consistently mislead all models simultaneously.
Fvpere0^92	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What is input filtering in AI security?	Input filtering examines incoming data for anomalies or suspicious patterns that could indicate adversarial manipulation, ensuring only validated data is processed by the model.
"CDC0u(2#P}"	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How can input filtering be applied to text models?	In text models, input filtering can remove unusual characters or patterns not typical of legitimate input, reducing vulnerability to evasion attacks.
u^,LTxMGrI	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What is backdoor detection in AI?	Backdoor detection involves identifying and removing malicious patterns embedded in training data or models that cause unintended or harmful outputs when triggered.
q0Cyr5HjD>	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How can feature importance be used for backdoor detection?	By analyzing feature importance values, developers can identify unusually influential features that may indicate backdoor behavior or data tampering.
Bge=uAW|~+	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What are monitoring and auditing in AI security?	Monitoring and auditing involve continuously observing AI system activity and periodically reviewing logs and configurations to ensure compliance, detect anomalies, and respond to potential threats.
g(cJz~}.hS	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	Why is real-time monitoring important in AI systems?	Real-time monitoring helps detect anomalies such as unusual data access or model predictions quickly, allowing prompt responses to prevent privacy breaches or attacks.
"Mx5mF@d!=#"	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What is the purpose of auditing AI systems?	Auditing verifies that AI systems adhere to ethical standards, privacy laws, and security protocols by analyzing records, testing vulnerabilities, and assessing compliance.
p^(U4eU}Kf	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How do monitoring and auditing complement each other?	Monitoring provides continuous oversight for detecting live issues, while auditing offers a retrospective analysis to evaluate overall compliance and system integrity.
Hb^=$syc&@	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	Why is AI security critical in healthcare and finance?	AI security is critical in these sectors because breaches or manipulated models can lead to misdiagnoses, financial fraud, or data exposure, causing severe harm to individuals and organizations.
BOJE4GVYc`	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What is the ultimate goal of privacy and security in responsible AI?	The ultimate goal is to ensure AI systems operate ethically, securely, and transparently, balancing innovation with the protection of individual rights and societal trust.
DzTKab_^Hi	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What is the purpose of threat modeling in cybersecurity?	Threat modeling is a proactive risk assessment approach that enumerates, analyzes, and prioritizes potential attacker-driven threats so teams can evaluate risk and plan mitigations before harm occurs; it reframes the system from the attacker’s point of view to surface weaknesses early.
i0RxfZIPb4	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How does integrating AI into user interfaces improve threat modeling outcomes?	Integrating AI into UI yields Intelligent User Interfaces (IUI) that perceive, learn, and adapt to user behavior, enabling automated anomaly detection, clearer explanations, and faster decision support at the point of interaction where threats often manifest.
lWDK_|h;z!	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	Why does the attacker’s point of view matter in modeling?	Thinking like an attacker identifies realistic paths, assets, and incentives, which improves coverage of threat scenarios and prevents defensive blind spots created by designer or operator assumptions.
oi^8=NVIUB	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What makes UI/UX relevant to security work, not just aesthetics?	UX governs trust, comprehension, and behavior; clear, user-centered UI reduces errors, elevates situational awareness, and improves adherence to secure workflows—outcomes as critical as cryptography or access control for real-world defenses.
phKNJ7oFt7	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How can poor HMI design increase security risk?	Poor HMI (e.g., raw numeric dumps, garish colors, no trends) overloads cognition, hides status, and fosters mistakes (like misreading units), increasing chances of insecure actions such as entering credentials on spoofed pages or ignoring critical alerts.
bY@2Z{HF)9	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What characteristics distinguish effective from poor HMIs?	Effective HMIs depict process status as information (not raw numbers), align layout with the operator’s mental model, show KPI trends, use low-contrast gray backgrounds with consistent coding, and minimize visual noise; these choices reduce error and increase trust.
MOT5z8>,S}	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	Why does trust in the interface directly affect security?	Users avoid sharing sensitive data or ignore warnings if they don’t trust the UI; conversely, a trustworthy interface improves compliance with secure actions (e.g., MFA enrollment) and reduces susceptibility to social engineering.
"mIq#1x@QY}"	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How can an intelligent interface reduce phishing success?	An IUI can detect suspicious features, warn proactively, and explain why a page is likely phishing (e.g., domain mismatches, form behavior), converting opaque blocks into teachable moments that improve future user judgment.
Il{Z;@SfQV	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What are the three main forms of UI used in security tools?	Graphical User Interfaces (GUI), Voice-Controlled User Interfaces (VUI), and Gesture-Based User Interfaces (GbUI) present security decisions visually, via speech, or through spatial gestures, respectively, broadening accessibility while introducing modality-specific risks.
FIh]{npeA2	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What are the three key UI elements designers must control?	Input controls (data entry), navigational controls (flow and wayfinding), and informational components (status and feedback) must work together to make risk visible and secure choices easy.
lnB*^fIH4C	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How does UX differ from UI in security contexts?	UI is the surface (layouts, controls), while UX is the lived experience of completing secure tasks over time; UX success is measured by clarity, confidence, error rates, recovery, and perceived safety across entire workflows.
jQVl~FDuSX	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	Why pair machine learning with UX for security?	ML enables adaptive experiences (e.g., dynamic friction, personalized warnings) based on learned patterns, while UX ensures those adaptations remain comprehensible, respectful, and effective for users.
t$l2(YK,^y	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What is an Intelligent User Interface (IUI)?	An IUI sits at the intersection of AI and HCI, embedding perception, learning, reasoning, and decision capabilities into the interface so the system can assist, adapt, and explain during human–machine security tasks.
"B[/+{g_9L#"	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	Give mainstream examples of IUI features users already know.	Smart Compose, conversational assistants (Alexa/Cortana), and recommender components exemplify IUIs that predict intent, propose actions, and adapt presentation in real time.
PJgb68HjVw	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What are common challenges when adding AI to UI for security?	Data privacy constraints, ethical integration, transparency of automated judgments, and avoiding over-automation that disempowers users are recurring challenges that must be addressed in design.
k**R~RXIJ(	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How can AI accelerate the classic UI development loop?	By translating sketches to code (e.g., CNN+LSTM-based recognizers), AI collapses the sketch→wireframe→code ladder into rapid prototypes, enabling more secure iterations with real users.
lq;pWsjzH:	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	Why does AI-enhanced prototyping matter for secure design?	Faster cycles mean earlier user testing of security-critical states (warnings, errors, recovery) and quicker removal of missteps that could otherwise become baked into shipped systems.
BG^XI7kAft	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How does repeated model performance build user trust?	Consistent, accurate assistance (e.g., flagging phishing reliably) conditions users to heed guidance; trustworthy behavior across time fosters reliance that strengthens overall security posture.
LERUDTl|W|	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What IUI techniques improve input collection for security apps?	Face/expression recognition, natural language understanding, gesture/gaze tracking, and context awareness let systems capture intent robustly and detect anomalies in how inputs are provided.
uSw}?ETB!Z	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What does “user modeling” mean in IUI for cyber tools?	User modeling captures preferences, abilities, context, and historical behavior so interfaces can adapt difficulty, explanations, and friction levels without surprising or frustrating users.
I__{Yk3DuJ	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	Why include “explanation generation” in security IUIs?	Explanations translate detections into human-relevant reasons (what, why, how certain), enabling informed choice, appeal, and learning; without them, users mistrust or ignore automation.
w8`Y3]?/8X	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How do direct and indirect manipulation differ for IUI?	Direct manipulation (immediate visible actions) has high intelligibility and usability but lower algorithmic predictability; indirect manipulation (system acts on inference) often raises predictability but can obscure system intent unless explained.
wEEi1_4j_0	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What are the three persistent IUI challenges?	Presentation (HCI: how to show and interact), competence (AI: how to infer and act), and trust (calibrating user confidence through transparency, control, and reliability).
A776_).pQ,	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What does “manage discovery and expectation” mean in IUI?	Set clear boundaries of capability and limits so users form accurate mental models; surprise automation with hidden rules undermines trust and increases misuse.
OM&X2QbvY^	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	Why should IUIs be designed to “forgive mistakes”?	AI will err; interfaces must support reversal, clarification, and graceful recovery (undo, confirm, edit), preserving dignity and preventing security incidents from minor slips.
wJt=x6ge/i	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How does “data transparency and customization” improve security?	Dashboards that show what data is collected/learned and controls to correct or opt out reduce privacy risk and help align automation with user intent.
Mr/gMuU4]-	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	Why are “privacy, security, and user control” baseline requirements?	Users must trust IUIs with sensitive data; offering clear privacy controls, secure data handling, and the ability to override automation fosters safe adoption.
m!+Ukv0Nm_	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What is the typical IUI processing pipeline?	Capture inputs → preprocess per modality → fuse signals → assess state/intent → adapt interface/actions → render outputs; assessment and adaptation often share an inference engine.
"A#-@Y6<{db"	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	When should threat modeling occur in the SDLC?	Early—at requirements and design—so security assumptions shape architecture, not just patch defects; early modeling is cheaper and more comprehensive than retrofits.
O4.|Qy:WZ-	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What are the five essential components of a practical threat modeling process?	According to the book Application of Artificial Intelligence in User Interfaces Design for Cyber Security Threat Modeling, the core components are threat intelligence (analysis), asset identification (determination), mitigation capability (countermeasures), risk assessment (vulnerability evaluation), and threat mapping (path/ranking).
yV;ECxaG@l	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How does “threat intelligence” differ from “threat mapping”?	Threat intelligence gathers sources, motivations, tools, and data flows; threat mapping charts attacker movement through assets to identify choke points and lateral paths.
L-lK!$$3?G	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	Why maintain an asset inventory for security UX?	Real-time inventories keep interfaces accurate—showing what exists, where it lives, and who depends on it—so alerts and mitigations reference concrete things users can act on.
bRv~uG:*y8	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What is “mitigation capability” in practice?	It’s the organization’s combined controls and skills (e.g., AV, EDR, detection logic, trained responders); gauging capacity reveals gaps and informs investment priorities.
c7CrW[!<EA	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How do risk assessments use active testing?	Penetration tests and continuous monitoring validate assumptions, uncover hidden paths, and quantify likelihood×impact to focus mitigation where it matters most.
Cb9Bnq7,f[	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What’s the value of threat ranking to teams?	Ranking aligns resources with expected loss; teams treat top risks first, reducing total exposure faster than distributing effort evenly.
eq4T?0:OKW	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	Why are hybrid threat models recommended in many cases?	According to the book, hybridizing methods covers more attack classes than any single model, balancing depth (e.g., STRIDE categories) with business impact (e.g., PASTA stages).
ol~Vve$jZ-	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	When is STRIDE especially useful?	Per the book, STRIDE is mature, easy to use, produces fewer false positives, and fits teams with limited security expertise needing structured, developer-friendly analysis.
yUc|_ysrv%	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	Why might PASTA be a strong default?	According to the book, PASTA’s well-structured, attacker/application focus and subsystem attribution enable high prioritization efficiency across stages in complex systems.
mz&490*fJ8	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	Where do Security Cards shine—and stumble?	They excel at brainstorming novel, sophisticated attacks but often produce many false positives; they work best with experienced facilitators and follow-up validation.
P]yA0=zihF	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What is Persona Non-Grata (PnG) modeling good for?	PnG analyzes user behavior and UI interactions to surface persona-driven misuse; it’s strong when weaknesses are known but harder when threat surfaces are unclear.
Rf|[$O6!l[	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How does QTMM differ from CVSS?	QTMM emphasizes rigorous documentation, scoring, and threat properties across stakeholders, while CVSS standardizes severity scores for vulnerabilities to aid triage and communication.
O)J@rOIo)D	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What practical metric can align risk discussions?	A simple score Risk = Likelihood × Impact can be normalized (e.g., 0–5 × 0–5 → 0–25) to rank scenarios, then refined with exposure and detectability.
pt,f-O2~D:	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How can ML aid threat determination in interfaces?	Models learn behavioral baselines (timing, sequences, inputs) and flag deviations at UI boundaries, enabling immediate, context-aware friction (step-up auth) and explanations.
B`&htpV4!W	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	Why was ML historically underused in HMI design?	Per the book, misconceptions, limited familiarity, and research gaps slowed adoption; modern data, compute, and libraries have removed many of those barriers.
j`@gm2%DlG	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How does predictive analytics reduce time-to-detection?	It mines large activity streams to identify patterns that precede incidents (precursors), enabling earlier warnings and targeted hardening before impact.
"vd1K&%!E[#"	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What are five AI-driven IUI design methods and their roles?	Probability-driven state-charts (predict next UI states), decision trees (rule-like choices per context), shortest-path prediction (frequent navigation flows), higher-order Markov models (sequence-aware next-step inference), and deep reinforcement learning (optimize long-run UX with reward signals).
t8(RGD!<6q	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	Give a plain-text example of a Markov-based next-step predictor.	State sequence s1→s2→s3…; predict s(t+1) that maximizes P(s(t+1) | s(t), s(t−1), …); higher-order models include multiple prior states to capture habits.
d^(Jqu@hAu	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How can deep RL personalize secure flows without harming UX?	Define rewards for safe completions, low error rates, and minimal friction; the agent learns policies π(a|s) that balance security (extra checks) with speed (few steps) per user context.
l87%@_9j2v	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	Why does “explanation at the edge” matter in IUIs?	Timely local explanations (why this step-up? why this block?) reduce abandonment, teach safe behaviors, and create feedback to improve models.
zxI6CIA%=L	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What trade-offs appear when comparing direct vs indirect manipulation?	Direct: high intelligibility/adaptation/usability; lower predictability. Indirect: higher predictability (automation), but lower intelligibility—mandating strong transparency and controls.
mj~gGZ^AF1	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How can designers evaluate IUI usability rigorously?	Track task time, error counts, recovery success, trust calibration, comprehension of explanations, and user satisfaction; iterate based on empirical findings.
"QBkZEy[(#b"	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What iterative steps help build a robust IUI?	Analyze users/application/environment → prototype interaction strategies → evaluate against criteria → correct and repeat → (optionally) extend design tools to support the new patterns.
k]t<;9lZu=	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How can uncontrolled APIs introduce risk into socio-technical systems?	External APIs invoked without engineering oversight can violate assumed invariants (availability, data quality, privacy), creating cascading risk in tightly coupled environments.
EnCnP^bc@:	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	Why is legal context relevant to IUI security design?	According to the book, over 142 countries have privacy/security laws; IUIs must communicate consent, data use, and rights clearly to satisfy diverse regulatory regimes.
jQ-hl:Z>V^	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How do UI choices reduce social-engineering success?	Designs that verify origins, show clear identity cues, and default to safe pathways (e.g., protected payment flows) blunt phishing and credential-theft attempts.
"E/2-nA#]bg"	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How should security be balanced with UX in enterprise tools?	Minimize integration complexity, align with human perception limits, and ensure controls fit existing workflows so security doesn’t force counterproductive workarounds.
r~R}HX~[{?	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How does asset identification support explainable alerts?	When alerts reference concrete assets (owner, location, dependencies), responders can act quickly; vague alerts are ignored or deferred.
l$XmtiRz0P	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What does “capacity of mitigation” look like on a dashboard?	A living matrix that maps threats to available controls, coverage, confidence, and owner; gaps trigger investment proposals and track progress.
RbI/^(qEE*	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How does penetration testing inform IUI design?	Findings reveal where users misunderstand flows, where warnings are missed, and where step-up auth is needed; IUIs are then adjusted to close those behavioral gaps.
L3RzDm&PO{	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What does good threat mapping reveal visually?	Lateral movement paths, choke points, and high-value assets; overlays can show likelihood, time-to-compromise, and existing controls to guide mitigation sequencing.
zY.5FgOyI@	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	Why use Multi-Criteria Decision Making (MCDM) to choose ML for IUI?	Because algorithm selection is subjective; MCDM balances accuracy, latency, interpretability, data needs, and privacy to pick fit-for-purpose models.
k76eCyg0|}	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What are credible AI-in-UI security products mentioned in the literature?	According to the book, examples include Darkrace Immune System–style anomaly detection, Vectra Cognito, Paladion for SOC automation, Codesealer for UI security, and AVATAR for automated deception detection during interviews.
yqtS%4.qQ4	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What attack classes does AI itself invite and how to mitigate?	Model evasion, data poisoning, and model extraction; mitigate with robust training, data validation, adversarial testing, monitoring, and controlled exposure.
dlVyZO-.+p	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	Why must Security Cards be followed by validation steps?	Their brainstorming power generates many hypotheticals; empirical testing, logging, and red-team exercises separate plausible threats from noise.
eB(NXWJ6.M	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How can affective computing help security UX?	By sensing stress/uncertainty and offering calmer explanations, extra guidance, or alternate channels, affect-aware IUIs can reduce error under pressure.
H(K]h_wO~K	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What does “treating systems as fellow beings” imply for IUI?	Design automation that communicates intentions, asks permission, and accepts correction—collaborative behavior that builds calibrated trust.
O//_8RO,C+	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How should IUIs present consent to satisfy privacy laws?	Plain language, specific purposes, retention windows, easy withdrawal, and real-time visibility into collected data and inferences.
"jp8KoFRT?#"	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What KPIs demonstrate improving security UX over time?	Reduced phishing click-through, shorter response times, higher successful recovery rates, improved comprehension of warnings, and increased adoption of secure defaults.
K-XVx>Z{O(	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How do recommender-style IUIs apply to security tooling?	They can suggest most-relevant alerts, likely root causes, or next best mitigation steps based on historical success, easing analyst overload.
kJgz&1,xn~	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What’s a safe default for ambiguous AI judgments at the UI?	Use “safe failure” patterns: constrain action, request more evidence (step-up auth), or escalate to human review while explaining the rationale.
"H:X]Os`9v#"	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How can IUIs self-calibrate user trust?	Track acceptance/override rates and post-action outcomes; if users frequently override correct advice, improve timing, clarity, or offer alternatives.
BjT?BM?MFQ	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What’s a practical way to express uncertainty in UI explanations?	Show qualitative bands (low/medium/high) plus a short reason and a suggested action; avoid raw model scores without context.
M1[8cBu4.Y	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How can shortest-path predictors simplify secure workflows?	By pre-positioning likely next actions, auto-filling safe defaults, and reducing clicks, shortest-path models lower friction while maintaining guardrails.
eOs(O{E8lM	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What makes higher-order Markov models valuable for detecting misuse?	They capture atypical sequence deviations (e.g., unusual order of admin pages), flagging misuse that single-step models would miss.
"QrS3j#H2%j"	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How can DRL avoid overfitting to risky shortcuts?	Include negative rewards for policy choices that increase risk (e.g., skipping verification) even if they reduce time, ensuring safety dominates speed in optimization.
o,>Ar^FmK1	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	How should security IUIs handle model updates ethically?	Communicate changes, provide before/after effects, allow opt-in phases, and supply rollback if adverse impacts are observed.
Q7WN<XL<jp	Basic	Launch into Computing::Unit 06 - Principles of Artificial Intelligence (AI)	What end-state does a mature AI-enabled security UI strive for?	A collaborative assistant that detects and explains risk, adapts to context and user, preserves privacy, and empowers swift, correct, and confident secure action.
